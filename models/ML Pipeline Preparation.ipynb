{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "\n",
    "## Project Workspace - Machine Learning Pipeline\n",
    "For the machine learning portion, you will:\n",
    "1. Split the data into a training set and a test set. \n",
    "2. Then, you will create a machine learning pipeline that uses: \n",
    "    - NLTK, \n",
    "    - Scikit-learn's Pipeline and GridSearchCV \n",
    "    - to output a final model that uses the message column to predict classifications for 36 categories (multi-output classification).\n",
    "3. Finally, you will export your model to a pickle file. After completing the notebook, you'll need to include your final machine learning code in ```train_classifier.py```.\n",
    "\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ahristian001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ahristian001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ahristian001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pd.set_option('max_rows', 4000)\n",
    "pd.set_option('max_columns', 4000)\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "pd.set_option('max_info_columns', 4000)\n",
    "pd.set_option('max_info_rows', 4000)\n",
    "pd.set_option('max_seq_items', 4000)\n",
    "pd.set_option('show_dimensions', True)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_file):\n",
    "    '''\n",
    "    INPUT\n",
    "        data_file - database filename\n",
    "    OUTPUT\n",
    "        X - input variables\n",
    "        y - target variables\n",
    "        category_names - message types\n",
    "    '''\n",
    "    \n",
    "    # load data from database\n",
    "    engine = create_engine(f'sqlite:///{data_file}')\n",
    "    # load to database\n",
    "    df = pd.read_sql(\"SELECT * FROM Message\", engine)\n",
    "    \n",
    "    # define features and label arrays\n",
    "    category_names = list(df.columns[4:])\n",
    "    X = df['message'].values\n",
    "    y = df[category_names].values\n",
    "    \n",
    "    return X, y, category_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, category_names = load_data('DisasterResponse.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    INPUT\n",
    "        text - one text message\n",
    "    OUTPUT\n",
    "        clean_tokens - clean normalised, tokenised and lemmatised text\n",
    "    '''\n",
    "    # Normalize text\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text.strip())\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_true, y_pred):\n",
    "    '''\n",
    "    INPUT\n",
    "        y_true - test labels\n",
    "        y_pred - predicted labels\n",
    "    '''\n",
    "    results_dict = dict()\n",
    "\n",
    "    for index, col in enumerate(cols):\n",
    "\n",
    "        # get model results as dictionary\n",
    "        report = classification_report(y_true[:, index], y_pred[:, index], zero_division=0, output_dict=True)\n",
    "        # get results from classification report\n",
    "        accuracy = report['accuracy'] \n",
    "        f1_score = report['weighted avg']['f1-score'] \n",
    "        precision = report['weighted avg']['precision'] \n",
    "        recall = report['weighted avg']['recall']\n",
    "        # set result in dictionary\n",
    "        results_dict[col] = {\n",
    "                'Accuracy': accuracy,\n",
    "                'F1-score': f1_score,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall\n",
    "        }\n",
    "\n",
    "    results = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    print('Aggregated results: ')\n",
    "    print(results.mean().to_string())\n",
    "    display(results) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_1 = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x000001F8201D84C0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier()))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "pipeline_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test, category_names):\n",
    "    '''\n",
    "    INPUT\n",
    "        model - trained model\n",
    "        X_test - inbut test variabels\n",
    "        Y_test - test labels\n",
    "        category_names - message types\n",
    "    '''\n",
    "    # predict on test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "    \n",
    "    results_dict = dict()\n",
    "\n",
    "    for index, col in enumerate(category_names):\n",
    "\n",
    "        # get model results as dictionary\n",
    "        report = classification_report(Y_test[:, index], Y_pred[:, index], zero_division=0, output_dict=True)\n",
    "        # get results from classification report\n",
    "        accuracy = report['accuracy'] \n",
    "        f1_score = report['weighted avg']['f1-score'] \n",
    "        precision = report['weighted avg']['precision'] \n",
    "        recall = report['weighted avg']['recall']\n",
    "        # set result in dictionary\n",
    "        results_dict[col] = {\n",
    "                'Accuracy': accuracy,\n",
    "                'F1-score': f1_score,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall\n",
    "        }\n",
    "\n",
    "    results = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "    print('Aggregated results: ')\n",
    "    print(results.mean().to_string())\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated results: \n",
      "Accuracy    0.948\n",
      "F1-score    0.935\n",
      "Precision   0.938\n",
      "Recall      0.948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.926</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.934</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.935</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.976</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.876</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.936</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.866</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  F1-score  Precision  Recall\n",
       "related                    0.805     0.771      0.798   0.805\n",
       "request                    0.898     0.884      0.896   0.898\n",
       "offer                      0.995     0.993      0.991   0.995\n",
       "aid_related                0.778     0.774      0.777   0.778\n",
       "medical_help               0.926     0.897      0.909   0.926\n",
       "medical_products           0.955     0.937      0.945   0.955\n",
       "search_and_rescue          0.973     0.962      0.965   0.973\n",
       "security                   0.980     0.971      0.961   0.980\n",
       "military                   0.968     0.953      0.956   0.968\n",
       "child_alone                1.000     1.000      1.000   1.000\n",
       "water                      0.954     0.942      0.951   0.954\n",
       "food                       0.934     0.924      0.930   0.934\n",
       "shelter                    0.935     0.921      0.930   0.935\n",
       "clothing                   0.987     0.983      0.985   0.987\n",
       "money                      0.976     0.966      0.974   0.976\n",
       "missing_people             0.990     0.985      0.980   0.990\n",
       "refugees                   0.970     0.956      0.967   0.970\n",
       "death                      0.961     0.947      0.957   0.961\n",
       "other_aid                  0.876     0.823      0.844   0.876\n",
       "infrastructure_related     0.936     0.906      0.877   0.936\n",
       "transport                  0.959     0.942      0.952   0.959\n",
       "buildings                  0.952     0.933      0.946   0.952\n",
       "electricity                0.981     0.972      0.963   0.981\n",
       "tools                      0.993     0.989      0.986   0.993\n",
       "hospitals                  0.991     0.987      0.982   0.991\n",
       "shops                      0.995     0.992      0.989   0.995\n",
       "aid_centers                0.989     0.984      0.978   0.989\n",
       "other_infrastructure       0.956     0.935      0.914   0.956\n",
       "weather_related            0.873     0.867      0.872   0.873\n",
       "floods                     0.951     0.943      0.950   0.951\n",
       "storm                      0.943     0.936      0.937   0.943\n",
       "fire                       0.988     0.983      0.977   0.988\n",
       "earthquake                 0.970     0.969      0.969   0.970\n",
       "cold                       0.983     0.977      0.981   0.983\n",
       "other_weather              0.947     0.922      0.928   0.947\n",
       "direct_report              0.866     0.844      0.863   0.866\n",
       "\n",
       "[36 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict on test data\n",
    "evaluate_model(pipeline_1, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x000001A229D5C4C0>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf', MultiOutputClassifier(estimator=RandomForestClassifier()))],\n",
       " 'verbose': False,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x000001A229D5C4C0>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier()),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__estimator': RandomForestClassifier(),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__max_depth': [5, 10, 15],\n",
    "    'clf__estimator__n_jobs':[ -1],\n",
    "    'clf__estimator__random_state': [17],\n",
    "    'clf__estimator__n_estimators': np.linspace(100, 500, 5, dtype=int),\n",
    "    'clf__estimator__min_samples_split': [2, 3, 4], #list(range(1, 8))\n",
    "    #'clf__estimator__verbose': [0]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline_1, param_grid=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'clf__estimator__max_depth': 5, 'clf__estimator__min_samples_split': 2, 'clf__estimator__n_estimators': 100, 'clf__estimator__n_jobs': -1, 'clf__estimator__random_state': 17}\n",
      "Wall time: 2h 24min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv.fit(X_train, y_train)\n",
    "print(\"Best Parameters:\", cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated results: \n",
      "Accuracy    0.928\n",
      "F1-score    0.896\n",
      "Precision   0.893\n",
      "Recall      0.928\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.761</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.831</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.919</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.972</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.981</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.967</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.895</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.983</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.955</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.869</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.937</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.979</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.996</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.611</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.910</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.907</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  F1-score  Precision  Recall\n",
       "related                    0.761     0.658      0.579   0.761\n",
       "request                    0.831     0.754      0.690   0.831\n",
       "offer                      0.995     0.993      0.991   0.995\n",
       "aid_related                0.594     0.448      0.747   0.594\n",
       "medical_help               0.919     0.881      0.926   0.919\n",
       "medical_products           0.949     0.924      0.900   0.949\n",
       "search_and_rescue          0.972     0.958      0.945   0.972\n",
       "security                   0.981     0.972      0.963   0.981\n",
       "military                   0.967     0.951      0.935   0.967\n",
       "child_alone                1.000     1.000      1.000   1.000\n",
       "water                      0.939     0.909      0.943   0.939\n",
       "food                       0.895     0.845      0.801   0.895\n",
       "shelter                    0.915     0.874      0.836   0.915\n",
       "clothing                   0.983     0.974      0.966   0.983\n",
       "money                      0.978     0.968      0.957   0.978\n",
       "missing_people             0.990     0.985      0.980   0.990\n",
       "refugees                   0.966     0.950      0.934   0.966\n",
       "death                      0.955     0.933      0.912   0.955\n",
       "other_aid                  0.869     0.808      0.756   0.869\n",
       "infrastructure_related     0.937     0.907      0.878   0.937\n",
       "transport                  0.953     0.930      0.908   0.953\n",
       "buildings                  0.956     0.935      0.914   0.956\n",
       "electricity                0.979     0.968      0.958   0.979\n",
       "tools                      0.995     0.992      0.995   0.995\n",
       "hospitals                  0.991     0.987      0.982   0.991\n",
       "shops                      0.996     0.993      0.991   0.996\n",
       "aid_centers                0.987     0.981      0.975   0.987\n",
       "other_infrastructure       0.959     0.939      0.919   0.959\n",
       "weather_related            0.725     0.611      0.801   0.725\n",
       "floods                     0.918     0.879      0.925   0.918\n",
       "storm                      0.910     0.867      0.828   0.910\n",
       "fire                       0.989     0.983      0.978   0.989\n",
       "earthquake                 0.907     0.863      0.823   0.907\n",
       "cold                       0.982     0.974      0.965   0.982\n",
       "other_weather              0.949     0.924      0.900   0.949\n",
       "direct_report              0.811     0.727      0.658   0.811\n",
       "\n",
       "[36 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(cv, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 54s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('txt_pipeline',\n",
       "                                                 Pipeline(steps=[('vect',\n",
       "                                                                  CountVectorizer()),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfTransformer())])),\n",
       "                                                ('txt_len',\n",
       "                                                 TextLengthExtractor())])),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=XGBClassifier(base_score=None,\n",
       "                                                               booster=None,\n",
       "                                                               colsample_bylevel=None,\n",
       "                                                               colsample_bynode=None,\n",
       "                                                               colsample_bytree=None,\n",
       "                                                               eval_metric='m...\n",
       "                                                               interaction_constraints=None,\n",
       "                                                               learning_rate=None,\n",
       "                                                               max_delta_step=None,\n",
       "                                                               max_depth=None,\n",
       "                                                               min_child_weight=None,\n",
       "                                                               missing=nan,\n",
       "                                                               monotone_constraints=None,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               num_parallel_tree=None,\n",
       "                                                               random_state=None,\n",
       "                                                               reg_alpha=None,\n",
       "                                                               reg_lambda=None,\n",
       "                                                               scale_pos_weight=None,\n",
       "                                                               subsample=None,\n",
       "                                                               tree_method=None,\n",
       "                                                               use_label_encoder=False,\n",
       "                                                               validate_parameters=None,\n",
       "                                                               verbosity=None)))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class TextLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "    A class to extend Sklearn's transformers to add the length of the text to the pipeline\n",
    "    '''\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Given an input text, return its length\n",
    "        \"\"\"\n",
    "        return pd.Series(X).apply(lambda x: len(x)).values.reshape(-1, 1)\n",
    "    \n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "                        ('features', FeatureUnion([\n",
    "                            ('txt_pipeline', Pipeline([\n",
    "                                ('vect', CountVectorizer()),\n",
    "                                ('tfidf', TfidfTransformer())\n",
    "                            ])),\n",
    "                            ('txt_len', TextLengthExtractor())\n",
    "                        ])),\n",
    "                        ('clf', MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'))) \n",
    "                    ])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, although I have used XGBoost, in the web app, I have used RandomForestClassifier. Please, feel free to try this model, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated results: \n",
      "Accuracy    0.952\n",
      "F1-score    0.945\n",
      "Precision   0.945\n",
      "Recall      0.952\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>related</th>\n",
       "      <td>0.817</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request</th>\n",
       "      <td>0.908</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_related</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_help</th>\n",
       "      <td>0.927</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical_products</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>search_and_rescue</th>\n",
       "      <td>0.973</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.980</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>military</th>\n",
       "      <td>0.970</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>child_alone</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>water</th>\n",
       "      <td>0.966</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shelter</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clothing</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>0.978</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_people</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugees</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>death</th>\n",
       "      <td>0.969</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_aid</th>\n",
       "      <td>0.881</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infrastructure_related</th>\n",
       "      <td>0.936</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transport</th>\n",
       "      <td>0.961</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buildings</th>\n",
       "      <td>0.960</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.982</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tools</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hospitals</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shops</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid_centers</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_infrastructure</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_related</th>\n",
       "      <td>0.880</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floods</th>\n",
       "      <td>0.959</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storm</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>0.990</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>0.971</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cold</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_weather</th>\n",
       "      <td>0.946</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>direct_report</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Accuracy  F1-score  Precision  Recall\n",
       "related                    0.817     0.800      0.804   0.817\n",
       "request                    0.908     0.903      0.903   0.908\n",
       "offer                      0.995     0.993      0.991   0.995\n",
       "aid_related                0.774     0.771      0.773   0.774\n",
       "medical_help               0.927     0.916      0.912   0.927\n",
       "medical_products           0.959     0.953      0.952   0.959\n",
       "search_and_rescue          0.973     0.967      0.965   0.973\n",
       "security                   0.980     0.971      0.968   0.980\n",
       "military                   0.970     0.966      0.964   0.970\n",
       "child_alone                1.000     1.000      1.000   1.000\n",
       "water                      0.966     0.965      0.965   0.966\n",
       "food                       0.950     0.949      0.949   0.950\n",
       "shelter                    0.950     0.947      0.946   0.950\n",
       "clothing                   0.990     0.989      0.989   0.990\n",
       "money                      0.978     0.975      0.974   0.978\n",
       "missing_people             0.990     0.987      0.987   0.990\n",
       "refugees                   0.971     0.965      0.964   0.971\n",
       "death                      0.969     0.967      0.966   0.969\n",
       "other_aid                  0.881     0.854      0.855   0.881\n",
       "infrastructure_related     0.936     0.913      0.910   0.936\n",
       "transport                  0.961     0.951      0.952   0.961\n",
       "buildings                  0.960     0.955      0.954   0.960\n",
       "electricity                0.982     0.977      0.976   0.982\n",
       "tools                      0.993     0.989      0.986   0.993\n",
       "hospitals                  0.991     0.987      0.985   0.991\n",
       "shops                      0.995     0.992      0.989   0.995\n",
       "aid_centers                0.988     0.984      0.982   0.988\n",
       "other_infrastructure       0.956     0.938      0.937   0.956\n",
       "weather_related            0.880     0.876      0.878   0.880\n",
       "floods                     0.959     0.955      0.956   0.959\n",
       "storm                      0.945     0.944      0.943   0.945\n",
       "fire                       0.990     0.988      0.988   0.990\n",
       "earthquake                 0.971     0.970      0.970   0.971\n",
       "cold                       0.984     0.982      0.981   0.984\n",
       "other_weather              0.946     0.930      0.927   0.946\n",
       "direct_report              0.871     0.861      0.862   0.871\n",
       "\n",
       "[36 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # predict and evaluate model on test data\n",
    "evaluate_model(pipeline, X_test, y_test, category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(pipeline, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
